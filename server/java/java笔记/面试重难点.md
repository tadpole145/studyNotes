## java知识点专题总结

[TOC]



### HashMap

#### HashMap的底层实现

在 JDK 1.7 中 HashMap 是以数组加链表的形式组成的，数组记录了每个链表的第一个节点. JDK 1.8 之后新增了红黑树的组成结构，当链表大于 8 并且数组容量大于 64 时，链表结构会转换成红黑树结构,数组中的元素被称为哈希桶. 

![image-20210720163456580](https://gitee.com/tadpole145/images/raw/main/20210720163504.png)

哈希桶,也就是数组中的元素,定义如下:

```java
static class Node<K,V> implements Map.Entry<K,V> {

    final int hash;

    final K key;

    V value;

    Node<K,V> next;  //下一个节点元素



    Node(int hash, K key, V value, Node<K,V> next) {

        this.hash = hash;

        this.key = key;

        this.value = value;

        this.next = next;

    }



    public final K getKey()        { return key; }

    public final V getValue()      { return value; }

    public final String toString() { return key + "=" + value; }



    public final int hashCode() {

        return Objects.hashCode(key) ^ Objects.hashCode(value);

    }



    public final V setValue(V newValue) {

        V oldValue = value;

        value = newValue;

        return oldValue;

    }



    public final boolean equals(Object o) {

        if (o == this)

            return true;

        if (o instanceof Map.Entry) {

            Map.Entry<?,?> e = (Map.Entry<?,?>)o;

            if (Objects.equals(key, e.getKey()) &&

                Objects.equals(value, e.getValue()))

                return true;

        }

        return false;

    }

}

```

此外,类初始化的时候,给了一些默认的属性值

```java
// HashMap 初始化长度
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; //  16

// HashMap 最大长度
static final int MAXIMUM_CAPACITY = 1 << 30; // 1073741824

// 默认的加载因子 (扩容因子)
static final float DEFAULT_LOAD_FACTOR = 0.75f;

// 当链表长度大于此值且数组容量大于 64 时
static final int TREEIFY_THRESHOLD = 8;

// 转换链表的临界值，当元素小于此值时，会将红黑树结构转换成链表结构
static final int UNTREEIFY_THRESHOLD = 6;

// 最小树容量
static final int MIN_TREEIFY_CAPACITY =64
```



 HashMap源码中主要的方法有get(Object key), put(K key, V value), resize()方法

#### put方法原理及知识点

##### 源码

```java
public V put(K key, V value) {

    // 对 key 进行哈希操作

    return putVal(hash(key), key, value, false, true);

}

final V putVal(int hash, K key, V value, boolean onlyIfAbsent,

               boolean evict) {

    Node<K,V>[] tab; Node<K,V> p; int n, i;

    // 哈希表为空则创建表

    if ((tab = table) == null || (n = tab.length) == 0)

        n = (tab = resize()).length;

    // 根据 key 的哈希值计算出要插入的数组索引 i

    if ((p = tab[i = (n - 1) & hash]) == null)

        // 如果 table[i] 等于 null，则直接插入

        tab[i] = newNode(hash, key, value, null);

    else {

        Node<K,V> e; K k;

        // 如果 key 已经存在了，直接覆盖 value

        if (p.hash == hash &&

            ((k = p.key) == key || (key != null && key.equals(k))))

            e = p;

        // 如果 key 不存在，判断是否为红黑树

        else if (p instanceof TreeNode)

            // 红黑树直接插入键值对

            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);

        else {

            // 为链表结构，循环准备插入

            for (int binCount = 0; ; ++binCount) {

                // 下一个元素为空时

                if ((e = p.next) == null) {

                    p.next = newNode(hash, key, value, null);

                    // 转换为红黑树进行处理

                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st

                        treeifyBin(tab, hash);

                    break;

                }

                //  key 已经存在直接覆盖 value

                if (e.hash == hash &&

                    ((k = e.key) == key || (key != null && key.equals(k))))

                    break;

                p = e;

            }

        }

        if (e != null) { // existing mapping for key

            V oldValue = e.value;

            if (!onlyIfAbsent || oldValue == null)

                e.value = value;

            afterNodeAccess(e);

            return oldValue;

        }

    }

    ++modCount;

    // 超过最大容量，扩容

    if (++size > threshold)

        resize();

    afterNodeInsertion(evict);

    return null;

}

```

put 流程简化如下:

1. 对 Key 求 Hash 值，然后再计算下标
2. 如果没有碰撞，直接放入桶中（碰撞的意思是计算得到的 Hash 值相同，需要放到同一个 bucket 中）
3. 如果碰撞了，以链表的方式链接到后面
4. 如果链表长度超过阀值（TREEIFY THRESHOLD==8并且容量超过MIN_TREEIFY_CAPACITY=64），就把链表转成红黑树，链表长度低于6，就把红黑树转回链表
5. 如果节点已经存在就替换旧值
6. 如果桶满了（容量16*加载因子0.75），就需要 resize（扩容2倍后重排）

![img](https://s0.lgstatic.com/i/image3/M01/73/D9/CgpOIF5rDYmATP43AAB3coc0R64799.png)



##### 如何获取待插入元素的数组索引

jdk8中,需要通过如下代码获取到待存入数据的索引

```java
// 找到元素在数组中的位置，n 为数组长度。
i = (n - 1) & hash

// 计算 Key 的 Hash 值 
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>>16);
}
//异或运算^:  相同则为0,不同则为1
```

###### 为什么 HashMap 数组的长度要是 2 的整数幂？

 **为了 减少哈希冲突并加快运算效率**

   hash是散列的意思, 我们希望任意一个 Key 落在数组中的位置是足够散列的，这样可以减少 Hash 碰撞的概率. 我们根据hash值得到的是一个int数,放置在一个16位长的数组中,如果想让它尽可能的散列分布,最简单的办法是 hash%n, 这样得到的余数就是数组的索引, 但是这样计算太低效了,由于计算机是二进制计算的,我们可以通过二进制的==与运算==,取其hash值的后几位就可以高效的得到散列值(也就是索引), 如: 

```java
    00100100 10100101 11000100 00100101    // Hash 值 
&   00000000 00000000 00000000 00001111    // 16 - 1 = 15
----------------------------------
    00000000 00000000 00000000 00000101    // 高位全部归零，只保留末四位。与运算不改变原hash值的低位数,这样散列程度只受参与运算的hash值影响.

```

假设是其它容量值,进行与运算的结果碰撞的概率就比较大, 比如当容量是10时,n-1=9 :

![img](https://gitee.com/tadpole145/images/raw/main/20210720173626.jpeg)

总的来说,因为计算机采用二进制,使用2的整数幂,在进行运算时候能大大提升效率.



###### HashMap中的hash算法是如何降低碰撞率的

上面我们已经知道,通过与运算取最后几位值,得到索引.但是int型的hash值,末尾数重复的太多了,为了解决这类问题，HashMap 想了一种办法（ *扰动* ）：将 Hash 值的高 16 位右移并与原 Hash 值取异或运算（^），混合高 16 位和低 16 位的值，得到一个更加散列的低 16 位的 Hash 值。如：

```java
00000000 00000000 00000000 00000101 // H1
00000000 00000000 00000000 00000000 // H1 >>> 16
00000000 00000000 00000000 00000101 // hash = H1 ^ (H1 >>> 16) = 5

00000000 11111111 00000000 00000101 // H2
00000000 00000000 00000000 11111111 // H2 >>> 16
00000000 00000000 00000000 11111010 // hash = H2 ^ (H2 >>> 16) = 250
//经过与运算求索引
index1 = (n - 1) & H1 = (16 - 1) & 5 = 5
index2 = (n - 1) & H2 = (16 - 1) & 250 = 10    
```



##### jdk1.8为啥引入红黑树, 为啥不直接全部变为红黑树, 转化成红黑树的条件是什么

同一个链表上的节点，它们的hash值计算出来都是一样的。但是如果hash冲突比较多的时候，生成的链表也会拉得比较长，这个时候检索起来就会退化成遍历操作，性能就比较低了。在Java 8中为了改善这种情况，引入了红黑树。红黑树是一种高级的平衡二叉树结构，其能保证查找、插入、删除的时间复杂度最坏为O(logn), 可以有效的解决链表过长时操作比较慢的问题。 

之所以选择红黑树是为了解决二叉查找树的缺陷：二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成层次很深的问题），遍历查找会非常慢。而红黑树在插入新数据后可能需要通过左旋、右旋、变色这些操作来保持平衡。引入红黑树就是为了查找数据快，解决链表查询深度的问题。我们知道红黑树属于平衡二叉树，为了保持“平衡”是需要付出代价的，但是该代价所损耗的资源要比遍历线性链表要少。所以当长度大于8的时候，会使用红黑树；如果链表长度很短的话，根本不需要引入红黑树，引入反而会慢。

当链表长度＞=8,且数组长度＞64时,才会转化成红黑树.只有在节点较多时,红黑树才能发挥它的优势.另外,如果满足链表长度＞8,而数组长度＜64,会被认为是桶分配的太少才产生那么多冲突的。那么此时应该选择扩容操作，以此来降低hash冲突的产生。等到数组的长度大于等于MIN_TREEIFY_CAPACITY的时候，如果当前链表的长度还是8的话，才会去转化成红黑树。

##### 说说你对红黑树的见解？

1.  每个节点非红即黑
2. 根节点总是黑色的
3. 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）
4. 每个叶子节点都是黑色的空节点（NIL节点）
5. 从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）



##### 链表转为红黑树的阈值是8，而红黑树退化成链表的阈值是6,为什么不一致呢

如果这两个值都为8的话，而当前链表的节点数量为7，此时一个新的节点进来了，计算出hash值和这七个节点的hash值相同，即发生了hash冲突。于是就会把这个节点挂在第七个节点的后面，但是此时已经达到了变成红黑树的阈值了（MIN_TREEIFY_CAPACITY条件假定也满足），于是就转成红黑树。

但是此时调用了一次remove操作需要删掉这个新加的节点，删掉之后当前红黑树的节点数量就又变成了7，于是就退化成了链表。然后此时又新加了一个节点，正好又要挂在第七个节点的后面，于是就又变成红黑树，然后又要remove，又退化成链表…可以看到在这种场景下，会不断地出现链表和红黑树之间的相互转换，这个性能是很低的，因为大部分的执行时间都花费在了转换数据结构上面

所以为了避免这种情况的发生，将两个阈值错开一些，以此来尽量避免在阈值点附近可能存在的、频繁地做转换数据结构操作而导致性能变低的情况出现。



#### get方法原理及其相关知识点

##### 源码

```java
public V get(Object key) {

    Node<K,V> e;

    // 对 key 进行哈希操作

    return (e = getNode(hash(key), key)) == null ? null : e.value;

}

final Node<K,V> getNode(int hash, Object key) {

    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;

    // 非空判断

    if ((tab = table) != null && (n = tab.length) > 0 &&

        (first = tab[(n - 1) & hash]) != null) {

        // 判断第一个元素是否是要查询的元素

        if (first.hash == hash && // always check first node

            ((k = first.key) == key || (key != null && key.equals(k))))

            return first;

        // 下一个节点非空判断

        if ((e = first.next) != null) {

            // 如果第一节点是树结构，则使用 getTreeNode 直接获取相应的数据

            if (first instanceof TreeNode)

                return ((TreeNode<K,V>)first).getTreeNode(hash, key);

            do { // 非树结构，循环节点判断

                // hash 相等并且 key 相同，则返回此节点

                if (e.hash == hash &&

                    ((k = e.key) == key || (key != null && key.equals(k))))

                    return e;

            } while ((e = e.next) != null);

        }

    }

    return null;

}

```

get 方法流程总结:

- 计算 key 的 hash 值。
- 如果存储数组不为空，且计算得到的位置上的元素不为空。继续，否则，返回 Null。
- 如果获取到的元素的 key 值相等，说明查找到了，返回元素。
- 如果获取到的元素的 key 值不相等，查找 next 节点的元素。
	- 如果元素是红黑树，在红黑树中查找。
	- 不是红黑树，遍历 next 节点查找，找到则返回。



#### resize()方法及其知识点

##### 源码

```java
static final int MAXIMUM_CAPACITY = 1 << 30;
static final float DEFAULT_LOAD_FACTOR = 0.75f;

final Node<K,V>[] resize() {

    // 扩容前的数组

    Node<K,V>[] oldTab = table;

    // 扩容前的数组的大小和阈值

    int oldCap = (oldTab == null) ? 0 : oldTab.length;

    int oldThr = threshold;

    // 预定义新数组的大小和阈值

    int newCap, newThr = 0;

    if (oldCap > 0) {

        // 超过最大值就不再扩容了

        if (oldCap >= MAXIMUM_CAPACITY) {

            threshold = Integer.MAX_VALUE;

            return oldTab;

        }

        // 扩大容量为当前容量的两倍，但不能超过 MAXIMUM_CAPACITY

        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&

                 oldCap >= DEFAULT_INITIAL_CAPACITY)

            newThr = oldThr << 1; // double threshold

    }

    // 当前数组没有数据，使用初始化的值

    else if (oldThr > 0) // initial capacity was placed in threshold

        newCap = oldThr;

    else {               // zero initial threshold signifies using defaults

        // 如果初始化的值为 0，则使用默认的初始化容量

        newCap = DEFAULT_INITIAL_CAPACITY;

        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);

    }

    // 如果新的容量等于 0

    if (newThr == 0) {

        float ft = (float)newCap * loadFactor;

        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?

                  (int)ft : Integer.MAX_VALUE);

    }

    threshold = newThr; 

    @SuppressWarnings({"rawtypes","unchecked"})

    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];

    // 开始扩容，将新的容量赋值给 table

    table = newTab;

    // 原数据不为空，将原数据复制到新 table 中

    if (oldTab != null) {

        // 根据容量循环数组，复制非空元素到新 table

        for (int j = 0; j < oldCap; ++j) {

            Node<K,V> e;

            if ((e = oldTab[j]) != null) {

                oldTab[j] = null;

                // 如果链表只有一个，则进行直接赋值

                if (e.next == null)

                    newTab[e.hash & (newCap - 1)] = e;

                else if (e instanceof TreeNode)

                    // 红黑树相关的操作

                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);

                else { // preserve order

                    // 链表复制，JDK 1.8 扩容优化部分
					// 把当前index对应的链表分成两个链表，减少扩容的迁移量
                    Node<K,V> loHead = null, loTail = null;

                    Node<K,V> hiHead = null, hiTail = null;

                    Node<K,V> next;

                    do {

                        next = e.next;

                        // 原索引

                        if ((e.hash & oldCap) == 0) {

                            if (loTail == null)

                                loHead = e;

                            else

                                loTail.next = e;

                            loTail = e;

                        }

                        // 原索引 + oldCap

                        else {

                            if (hiTail == null)

                                hiHead = e;

                            else

                                hiTail.next = e;

                            hiTail = e;

                        }

                    } while ((e = next) != null);

                    // 将原索引放到哈希桶中

                    if (loTail != null) {

                        loTail.next = null;

                        newTab[j] = loHead;

                    }

                    // 将原索引 + oldCap 放到哈希桶中

                    if (hiTail != null) {

                        hiTail.next = null;

                        newTab[j + oldCap] = hiHead;

                    }

                }

            }

        }
    }

    return newTab;
}

```

resize方法执行流程如下:

1. 记录下扩容前的数组,及其大小和阈值, 初始化新数组及其阈值
2. 对原数组的大小及其阈值进行校验
	1. oldCap超过最大值就不再扩容了
	2. 扩大容量为当前容量的两倍，但不能超过 MAXIMUM_CAPACITY
	3. 如果初始化的值为 0，则使用数组默认的初始化容量16
3. 开始扩容，创建一个长度为newCap的newTab.
4. 根据oldCap遍历数组，复制非空元素到新 table
	1. 如果链表只有一个，则进行直接赋值, 重新计算在新数组中的索引e.hash & (newCap - 1)
	2. 如果是红黑树,则执行红黑树相关操作
	3. 如果是链表,则根据e.hash & oldCap 得到的结果来决定是否移动索引位置



##### 什么是加载因子？加载因子为什么是 0.75？

加载因子也叫扩容因子或负载因子，用来判断什么时候进行扩容的，假如加载因子是 0.5，HashMap 的初始化容量是 16，那么当 HashMap 中有 16*0.5=8 个元素时，HashMap 就会进行扩容。

那加载因子为什么是 0.75 而不是 0.5 或者 1.0 呢？

这其实是出于容量和性能之间平衡的结果：

当加载因子设置比较大的时候，扩容的门槛就被提高了，扩容发生的频率比较低，占用的空间会比较小，但此时发生 Hash 冲突的几率就会提升，因此需要更复杂的数据结构来存储元素，这样对元素的操作时间就会增加，运行效率也会因此降低；

而当加载因子值比较小的时候，扩容的门槛会比较低，因此会占用更多的空间，此时元素的存储就比较稀疏，发生哈希冲突的可能性就比较小，因此操作性能会比较高。

所以综合了以上情况就取了一个 0.5 到 1.0 的平均数 0.75 作为加载因子。



##### 如何理解jdk1.8中的扩容后的链表移动机制

正常情况下，计算节点在table中的下标的方法是：hash&(oldTable.length-1)，扩容之后，table长度翻倍，计算table下标的方法是hash&(newTable.length-1)，也就是hash&(oldTable.length*2-1)，于是我们有了这样的结论：这新旧两次计算下标的结果，要不然就相同，要不然就是新下标等于旧下标加上旧数组的长度。

举例:  假设table原长度是16，扩容后长度32，那么一个hash值在扩容前后的table下标是这么计算的：

![img](https://gitee.com/tadpole145/images/raw/main/20210721154935.jpeg)

hash和新旧table按位与的结果，最后4位显然是相同的，唯一可能出现的区别就在第5位，也就是hash值的b所在的那一位，如果b所在的那一位是0，那么新table按位与的结果和旧table的结果就相同，反之如果b所在的那一位是1，则新table按位与的结果就比旧table的结果多了10000（二进制），而这个二进制10000就是旧table的长度16。

换言之，hash值的新散列下标是不是需要加上旧table长度，只需要看看hash值第5位是不是1就行了，位运算的方法就是hash值和10000（也就是旧table长度）来按位与，其结果只可能是10000或者00000。

所以,源码使用e.hash & oldCap，就是用于计算位置b到底是0还是1用的，只要其结果是0，则新散列下标就等于原散列下标，否则新散列坐标要在原散列坐标的基础上加上原table长度。

![img](https://s0.lgstatic.com/i/image3/M01/73/D9/Cgq2xl5rDYmAXoWFAAArXO_oe8c713.png)

##### HashMap扩容时候的死锁问题

在Java 7的HashMap源码中，transfer方法是用来做扩容时的迁移数据操作的。其实现就是通过遍历链表中的每一个节点，重新rehash实现的。在这其中会涉及到指针的修改，在高并发的场景下，可能会使链表上的一个节点的下一个指针指向了其前一个节点，也就是形成了死循环

而Java8中通过形成两个链表，节点hash值在数组容量二进制数为1的那个位置处去按位与判断是0还是1，以此来选择插入的方式很好地解决了这个问题，而且不用每一个节点rehash，提高了执行速度。

 HashMap 本身就是非线程安全的，如果要在多线程下，建议使用 ConcurrentHashMap 替代.







#### 参考文献

[聊聊经典数据结构HashMap,逐行分析每一个关键点](https://baijiahao.baidu.com/s?id=1679219630514764243&wfr=spider&for=pc)

[详解 HashMap 中的 Hash 算法（扰动函数）](https://zhangzw.com/posts/20190925.html)

[终结HashMap面试？我是谁？我在哪](https://zhuanlan.zhihu.com/p/77899892)

[面试中最喜欢问的HashMap知识都在这里，赶紧收藏！](https://baijiahao.baidu.com/s?id=1662733945029523270&wfr=spider&for=pc)

[Java集合之一—HashMap](https://blog.csdn.net/woshimaxiao1/article/details/83661464)

java源码剖析34讲

[Hashmap实现原理及扩容机制详解](https://blog.csdn.net/lkforce/article/details/89521318)

